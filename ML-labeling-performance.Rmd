---
title: "Decaying_curve"
author: "Ngoc Nguyen"
date: "2024-01-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("Functions_for_Spectral_Clustering.R")
```

#Relabeling the data with just the first 2 days of the pulses
```{r}
ori_dir <- "/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/DT_interpolated_datasets_all_pulse/"
df_manual <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Data/Birch-effect-high_pulse_intensity.csv")
#df_manual <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Data/Birch effect Manual Label - shortcut.csv")
df_manual$SOP <- as.Date(df_manual$SOP)
df_manual$EOP <- as.Date(df_manual$EOP)

file_list <- list.files(ori_dir)
df_list <- list()

for(i in 1:length(file_list)) {
  ##Reading each file
  file_path <- paste(ori_dir, file_list[i], sep = "")
  df_full <- read.csv(file_path, header = TRUE)
  df_full$Time <- as.Date(df_full$Time)
  site_name <- substr(file_list[i], start = 1, stop = 6)
  
  pulse_df <- subset(df_manual, SITE_ID == site_name)
  tryCatch ({
  #calculating pulse magnitude and duration
  all_pulse_first_day <- c()
  day_index <- c()
  for(j in 1:nrow(pulse_df)) {
    all_pulse_first_day <- append(all_pulse_first_day, as.Date(pulse_df$SOP[j]:pulse_df$SOP[j] + 1))
    day_index <- append(day_index, 1:2)
  }

  df_full$RECO_pulse_initial <- 0
  df_full$RECO_pulse_initial[which(df_full$Time %in% all_pulse_first_day)] <- 1
  
  file_name <- paste("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/pulse_intensity_filter_binary/", site_name, ".csv", sep="")
  write.csv(df_full, file_name)
  }, error = function(err) { })
}
```

#draw feature importance of ML 
```{r}
df_impo <- read.csv('/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/Random_forest/28_sites_Feature_Impo_Sept13.csv')

colnames(df_impo) <- c("Importance_score", "std")
df_impo$Feature <- c("Month", "NT modeled Reco", "NEE","EF", "P_ERA", "ΔEF", "Pre_pulse_EF", "ΔNEE","Pre_pulse_NEE", "Daily NEE") 

png("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Figures/19_sites_manual/ML_feature_impo_Sept13.png",  width     = 5.5,
    height    = 7,
    units     = "in",
    res       = 1200,
    pointsize = 4)

ggplot(df_impo, aes(x = Importance_score, y = reorder(Feature, Importance_score))) + geom_bar_pattern(stat = "identity", fill = "white", pattern = 'stripe', pattern_spacing = 0.05, pattern_color = "#3c5488", color = "#3c5488", alpha = 0.7) +
    geom_errorbar(aes(xmin = Importance_score - std, xmax = Importance_score + std),
                width = 0.2, colour = "#3c5488", size = 0.8) +
  theme_bw() + 
  theme(
  axis.text.y = element_text(size = 15),
  axis.text.x = element_text(hjust = 1, size = 15),
  axis.title.y = element_text(size = 15),
  axis.title.x = element_text(size = 15),
  legend.key.size = unit(1, 'cm'),
  legend.text = element_text(size=13),
  legend.title = element_text(size=13),
  panel.grid.major = element_blank() , panel.grid.minor = element_blank()) +
  ylab("Feature") + xlab("Feature importance score") 
dev.off()
```

#Acquire ML labelled data
```{r}
dir <- "/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/Random_forest/non-training-sites/Manual-ML-pulse-SOP-EOP/"
file_list <- list.files(dir)
df_list <- list()

for(j in 1:length(file_list)) {
  ##Reading each file
  file_path <- paste(dir, file_list[j], sep = "")
  df_full <- read.csv(file_path, header = TRUE)
  site_name <- substr(file_list[j], start = 1, stop = 6)
  if(nrow(df_full) != 0) {
    df_full$SITE_ID <- site_name
    df_list[[j]] <- df_full
  }
}

all_pulse_df <- NULL
for(i in 1:length(df_list)) {
  all_pulse_df <- rbind(all_pulse_df, df_list[[i]])
}
write.csv(all_pulse_df, "/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/ML-label-collection-add_NEE.csv")
```


```{r}
#Compare ML and manual-labelled performance
#ML
#ML_label <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/Random_forest/non-training-sites/ML-pulse-decay-info/SOP-EOP-ML.csv")
ML_label <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/Random_forest/non-training-sites/ML-pulse-decay-info/ML_ori_NEE_SOP_7_filter.csv")
ML_label$SOP <- as.Date(ML_label$SOP)
ML_label$EOP <- as.Date(ML_label$EOP)

#Manual 
manual_label <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Data/Birch effect Manual Label - shortcut.csv")
manual_label$SOP <- as.Date(manual_label$SOP)
manual_label$EOP <- as.Date(manual_label$EOP)
manual_label <- manual_label[order(manual_label$SITE_ID), ]
  
df_tot_C <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/3vars_all_sites.csv")
df_tot_C$SOP <- as.Date(df_tot_C$SOP)

manual_label_bind <- left_join(manual_label, df_tot_C, by = c("SOP", "SITE_ID"))

exclude_site <-  c("AU-DaS", 'AU-Gin', 'AU-Rig', 'US-FR2', 'US-xNG', 'AU-Dry')
manual_label <- subset(manual_label_bind, !(SITE_ID %in% exclude_site))
ML_label <- subset(ML_label, SITE_ID %in% unique(manual_label$SITE_ID))
```

```{r}
SOP_accuracy_list <- list()
site_list <- unique(manual_label$SITE_ID)

for(i in 1:length(site_list)) {
  tryCatch({
    #subset for a specific site
  ML_label_sub <- subset(ML_label, SITE_ID == site_list[i])
  manual_label_sub <- subset(manual_label, SITE_ID ==  site_list[i])
  
  #obtain data for the last 3 years only
  manual_label_sub$Year <- as.numeric(format(manual_label_sub$SOP,"%Y"))
  ML_label_sub$Year <- as.numeric(format(ML_label_sub$SOP,"%Y"))
  max_year <- max(manual_label_sub$Year)
  year_test <- c(max_year, max_year - 1, max_year - 2)
  
  ML_label_sub_test <- subset(ML_label_sub, Year %in% year_test)
  manual_label_sub_test <- subset(manual_label_sub, Year %in% year_test)
  
  #obtain pulses that are missed and pulses that are not missed
  SOP_ML_list <- c(ML_label_sub_test$SOP, ML_label_sub_test$SOP + 1, ML_label_sub_test$SOP - 1,ML_label_sub_test$SOP + 2, ML_label_sub_test$SOP - 2)
  
  SOP_accuracy <- c()
  SOP <- c()
  for(j in 1:length(manual_label_sub_test$SOP)) {
    SOP <- append(SOP, manual_label_sub_test$SOP[j])
    if(manual_label_sub_test$SOP[j] %in% SOP_ML_list) {
      SOP_accuracy <- append(SOP_accuracy, 1)
    } else {
      SOP_accuracy <- append(SOP_accuracy, 0)
    }
  }
  df_result <- data.frame(SOP, SOP_accuracy)
  df_result$SITE_ID <- site_list[i]
  SOP_accuracy_list[[i]] <- df_result
  
  }, error = function(err) { })
}
  all_result_df <- NULL
  for(i in 1:length(SOP_accuracy_list)) {
    all_result_df <- rbind(all_result_df, SOP_accuracy_list[[i]])
  }       


df_merged_C <- left_join(all_result_df, manual_label_bind, by = c("SOP", "SITE_ID"))
df_merged_C <- subset(df_merged_C, change_NEE > 3.28)

ggplot(df_merged_C, aes(x = as.factor(SOP_accuracy), y = change_NEE, fill = as.factor(SOP_accuracy), color = as.factor(SOP_accuracy))) + geom_boxplot(outlier.shape = NA, alpha = 0.3) + theme_bw() + geom_jitter() +
  scale_fill_manual(values=c("#3c5488", "#00a087", "#f39b7f", "#f45b7f", "#f50b7f")) +
  scale_color_manual(values=c("#3c5488", "#00a087", "#f39b7f", "#f45b7f", "#f50b7f"))

#t-test 
accurate <- subset(df_merged_C, SOP_accuracy == 1)
wrong <- subset(df_merged_C, SOP_accuracy == 0)
nrow(accurate)/(nrow(accurate) + nrow(wrong))

#plot sites that has wrong labelled
num_zeros <- apply(wrong, 2, function(x) sum(x == 0))

# Combine the column names with their zero counts into a descriptive format
zero_counts <- wrong %>%
  group_by(SITE_ID) %>%
  summarise(ZeroCount = sum(SOP_accuracy == 0))
accurate
wrong
```

#Calculate precision and recall
```{r}
# Function to check if observed dates are within tolerance of predicted date
within_tolerance <- function(pred_date, obs_dates) {
  any(abs(difftime(obs_dates, pred_date, units = "days")) <= tolerance)
}
site_list <- unique(manual_label$SITE_ID)
precision_list <- c()
recall_list <- c()
SITE_list <- c()

for(i in 1:length(site_list)) {
  site_name = site_list[i]
  ML_label_sub <- subset(ML_label, SITE_ID == site_name)
  manual_label_sub <- subset(manual_label, SITE_ID ==  site_name)
  
  #obtain data for the last 3 years only
  manual_label_sub$Year <- as.numeric(format(manual_label_sub$SOP,"%Y"))
  ML_label_sub$Year <- as.numeric(format(ML_label_sub$SOP,"%Y"))
  max_year <- max(manual_label_sub$Year)
  year_test <- c(max_year, max_year - 1, max_year - 2)
  
  ML_label_sub_test <- subset(ML_label_sub, Year %in% year_test)
  manual_label_sub_test <- subset(manual_label_sub, Year %in% year_test)
# Tolerance in days
tolerance <- 2

tryCatch({
# Calculate matches
ML_label_sub_test$SOP_match <- sapply(ML_label_sub_test$SOP, function(x) within_tolerance(x, manual_label_sub_test$SOP))

# True Positives: Predicted dates that have a matching observed date
true_positives <- sum(ML_label_sub_test$SOP_match)

# False Positives: Predicted dates with no matching observed date
false_positives <- nrow(ML_label_sub_test) - true_positives

# False Negatives: Observed dates that do not have a matching predicted date
false_negatives <- sum(!sapply(manual_label_sub_test$SOP, function(x) within_tolerance(x, ML_label_sub_test$SOP)))

# Precision and Recall
precision <- true_positives / (true_positives + false_positives)
recall <- true_positives / (true_positives + false_negatives)

# # Display results
# print(paste("Precision:", precision))
# print(paste("Recall:", recall))
# print(site_name)

#add the result to the array
precision_list <- append(precision_list, precision)
recall_list <- append(recall_list, recall)
SITE_list <- append(SITE_list, site_name)
  }, error = function(err) { })
}

df_metric <- data.frame(SITE_list, precision_list, recall_list)
colnames(df_metric) <- c("SITE_ID", "Precision", "Recall")

library(ggpattern)
metric_melt_jitter = melt(df_metric)
metric_melt_jitter$xj <- jitter(as.numeric(factor(melt(df_metric)$variable)))

png("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Figures/19_sites_manual/ML_compare_site_reduce_imbalanced.png",  width     = 4.75,
    height    = 5.3,
    units     = "in",
    res       = 1200,
    pointsize = 4)
#plot the boxplot of performance metric across sites
ggplot(metric_melt_jitter, aes(x = xj, y = value, group = variable)) + 
  theme_bw() +
  geom_boxplot(outlier.shape = NA, fill = "white", color = "black", alpha = 0.5) +
  geom_point(width = 0.15, height = 0, color = "blue", size = 3, alpha = 0.5) +
ylim(0, 1) + 
  theme(
    panel.grid.major = element_blank(),  # Removes major grid lines
    panel.grid.minor = element_blank()   # Removes minor grid lines
  )
dev.off()
#geom_text_repel(
    aes(label = SITE_ID), color = "black",
    box.padding = 0.4,
    point.padding = 0.01,
    segment.color = 'gray50',
    force = 30,
    min.segment.length = 0
  )


png("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Figures/19_sites_manual/ML_compare_site_reduce_imbalanced_scatter_plot.png",  width     = 5,
    height    = 5,
    units     = "in",
    res       = 1200,
    pointsize = 4)
ggplot(df_metric, aes(Precision, Recall)) + geom_point(size = 3, color = "blue", alpha = 0.5) + theme_bw() + ylim(0, 1) + xlim(0, 1) + geom_text_repel(
    aes(label = SITE_ID), color = "black",
    box.padding = 1,
    point.padding = 1,
    segment.color = 'black',
    force = 50,
    min.segment.length = 0
  ) +   theme(
    panel.grid.major = element_blank(),  # Removes major grid lines
    panel.grid.minor = element_blank()   # Removes minor grid lines
  )
dev.off()
```
#train on > 5.05 pulse, < 5.05 pulse
#remove excess 0 points to make the dataset less imbalanced

#calculating precision and recall across a gradient of C contribution 
```{r}
precision_list <- c()
recall_list <- c()
threshold_list <- c()
pulse_num <- c()
false_positive_list <- c()
for(threshold in seq(-20, 15, by = 5) ) {
  #seq(-27, 22, by = 0.1)
site_list <- unique(manual_label$SITE_ID)
true_positives_list <- c()
false_positives_list <- c()
false_negatives_list <- c()
pulse_number_list <- c()
  #tryCatch({
for(i in 1:length(site_list)) {
  site_name = site_list[i]
  ML_label_sub <- subset(ML_label, SITE_ID == site_name)
  manual_label_sub <- subset(manual_label, SITE_ID ==  site_name)
  
  #obtain data for the last 3 years only
  manual_label_sub$Year <- as.numeric(format(manual_label_sub$SOP,"%Y"))
  ML_label_sub$Year <- as.numeric(format(ML_label_sub$SOP,"%Y"))
  max_year <- max(manual_label_sub$Year)
  year_test <- c(max_year, max_year - 1, max_year - 2)
  
  ML_label_sub_test <- subset(ML_label_sub, Year %in% year_test)
  manual_label_sub_test <- subset(manual_label_sub, Year %in% year_test & C_contribution > threshold & C_contribution <= (threshold + 5))
  pulse_number <- nrow(manual_label_sub_test)
  # Tolerance in days
  tolerance <- 2
  

  # Calculate matches
  ML_label_sub_test$SOP_match <- sapply(ML_label_sub_test$SOP, function(x) within_tolerance(x, manual_label_sub_test$SOP))
  
  # True Positives: Predicted dates that have a matching observed date
  true_positives <- sum(ML_label_sub_test$SOP_match)
  
  # False Positives: Predicted dates with no matching observed date
  false_positives <- nrow(ML_label_sub_test) - true_positives
  # False Negatives: Observed dates that do not have a matching predicted date
  false_negatives <- sum(!sapply(manual_label_sub_test$SOP, function(x) within_tolerance(x, ML_label_sub_test$SOP)))
  
  #add the result to the array
  true_positives_list <- append(true_positives_list, true_positives)
  false_positives_list <- append(false_positives_list, false_positives)
  false_negatives_list <- append(false_negatives_list, false_negatives)
  pulse_number_list <- append(pulse_number_list, pulse_number)
}

true_positives_tot <- sum(true_positives_list)
false_positives_tot <- sum(false_positives_list)
false_negatives_tot <- sum(false_negatives_list)
pulse_number_tot <- sum(pulse_number_list)

precision <- true_positives_tot/(true_positives_tot + false_positives_tot)
recall <- true_positives_tot/(true_positives_tot + false_negatives_tot)

precision_list <- append(precision_list, precision)
recall_list <- append(recall_list, recall)
threshold_list <- append(threshold_list, threshold)
pulse_num <- append(pulse_num, pulse_number_tot)
false_positive_list <- append(false_positive_list, false_positives_tot)
 # }, error = function(err) { })
}

df_metric_threshold <- data.frame(threshold_list, precision_list, recall_list, pulse_num, false_positive_list)
df_metric_threshold$pulse_num_per <- df_metric_threshold$pulse_num/max(df_metric_threshold$pulse_num)

# precision_metric <- df_metric_threshold$precision_list
# pulse_num_per_metric <- df_metric_threshold$pulse_num_per
# threshold_metric <-  df_metric_threshold$threshold_list
# 
# recall_metric <- df_metric_threshold$recall_list
# precision_2 <- df_metric_threshold$precision_list
# df_metric <- data.frame(precision_metric, recall_metric, pulse_num_per_metric, threshold_metric, precision_2)
```


```{r}
png("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Figures/19_sites_manual/C_contribution_ML_performance_5.png",  width     = 3.25,
    height    = 3.5,
    units     = "in",
    res       = 1200,
    pointsize = 4)
ggplot(df_metric_threshold, aes(threshold_list)) +
    geom_point(aes(y = recall_list), color = "blue", linewidth = 1, alpha = 0.8) + 
    geom_line(aes(y = pulse_num/491), linewidth = 1, alpha = 0.8) + theme_bw() +
  scale_y_continuous(
    name = "Precision of pulse < threshold",
    sec.axis = sec_axis(~.*491, name="Pulse number")) +  theme(
    panel.grid.major = element_blank(),  # Removes major grid lines
    panel.grid.minor = element_blank()   # Removes minor grid lines
  ) + geom_vline(xintercept = 0, linetype = 6) + xlab("Pulse Intensity") +
  xlim(-10, 15)
dev.off()

#draw bar graph
png("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Figures/19_sites_manual/pulse_definition.png",  width     = 3,
    height    = 3.5,
    units     = "in",
    res       = 1200,
    pointsize = 4)
ggplot(df_metric_threshold, aes(threshold_list+2.5, recall_list)) + geom_bar(stat = "identity", color = "#3c5488", fill = "#3c5488", alpha = 0.5) + theme_bw() + xlim(-20, 20) + ylim(0, 1) + theme(
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank())  + scale_x_continuous(breaks = seq(-20, 20, by = 5)) + geom_vline(xintercept = 0, linetype = 6)
dev.off()


df_metric_threshold
```


```{r}
subset(manual_label_bind, change_NEE > 1.22)
##464 sites. Test on them

write.csv(subset(manual_label_bind, C_contribution > 5.05), "/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Data/Birch-effect-high_pulse_intensity.csv")
```


#Difference way to calculate recall across C gradient
```{r}
precision_list <- c()
recall_list <- c()
threshold_list <- c()

for(threshold in seq(0, 8, by = 0.01)) {
true_positives_list <- c()
false_positives_list <- c()
false_negatives_list <- c()
for(i in 1:length(site_list)) {
    #subset for a specific site
  ML_label_sub <- subset(ML_label, SITE_ID == site_list[i])
  manual_label_sub <- subset(manual_label, SITE_ID ==  site_list[i])
  
  #obtain data for the last 3 years only
  manual_label_sub$Year <- as.numeric(format(manual_label_sub$SOP,"%Y"))
  ML_label_sub$Year <- as.numeric(format(ML_label_sub$SOP,"%Y"))
  max_year <- max(manual_label_sub$Year)
  year_test <- c(max_year, max_year - 1, max_year - 2)
  
  ML_label_sub_test <- subset(ML_label_sub, Year %in% year_test)
  manual_label_sub_test <- subset(manual_label_sub, Year %in% year_test & C_contribution >= threshold)
  
  #true_positive, false_negative
  SOP_ML_list <- c(ML_label_sub_test$SOP, ML_label_sub_test$SOP + 1, ML_label_sub_test$SOP - 1, ML_label_sub_test$SOP + 2, ML_label_sub_test$SOP - 2)
  true_positive <- count(manual_label_sub_test$SOP %in% SOP_ML_list)$freq[2] 
  false_negative <- count(manual_label_sub_test$SOP %in% SOP_ML_list)$freq[1] 


    # Check for false_positive
  SOP_manual_list <- c(manual_label_sub_test$SOP, manual_label_sub_test$SOP + 1, manual_label_sub_test$SOP - 1, manual_label_sub_test$SOP + 2, manual_label_sub_test$SOP - 2)
  false_positive <- count(ML_label_sub_test$SOP %in% SOP_manual_list)$freq[1] 
  
}
  true_positives_list <- append(true_positives_list, true_positive)
  false_positives_list <- append(false_positives_list, false_positive)
  false_negatives_list <- append(false_negatives_list, false_negative)
  
true_positives_tot <- sum(true_positives_list)
false_positives_tot <- sum(false_positives_list)
false_negatives_tot <- sum(false_negatives_list)

precision <- true_positives_tot/(true_positives_tot + false_positives_tot)
recall <- true_positives_tot/(true_positives_tot + false_negatives_tot)

precision_list <- append(precision_list, precision)
recall_list <- append(recall_list, recall)
threshold_list <- append(threshold_list, threshold)

}

df_metric_threshold <- data.frame(threshold_list, precision_list, recall_list)

ggplot(df_metric_threshold, aes(threshold_list, recall_list)) + geom_line() + theme_bw()
max(df_metric_threshold$recall_list)
df_metric_threshold
```


#extract sites with low C and site with high C
```{r}
df_rela <- read.csv("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Datasets/Rela_Imp_dataset.csv")
df_rela$SITE_ID[which(df_rela$C_contribution < 0)]
```

```{r}
# Function to calculate accuracy
calculate_accuracy <- function(threshold, data) {
  data_sub <- subset(data, change_NEE >= threshold)
  accuracy <- nrow(subset(data_sub, SOP_accuracy == 1))/nrow(data_sub)
  return(accuracy)
}

# Testing different thresholds
thresholds <- seq(0, 5, by = 0.01)  # Adjust step size based on your data range and desired precision

accuracies <- sapply(thresholds, calculate_accuracy, data = df_merged_C)

# Finding the optimal threshold
optimal_threshold <- thresholds[which.max(accuracies)]
max_accuracy <- max(accuracies)

# Output the optimal threshold and its accuracy
print(paste("Optimal threshold: ", optimal_threshold))
print(paste("Maximum accuracy: ", max_accuracy))

df <- data.frame(thresholds, accuracies)
# Optional: Plotting the accuracies for visual inspection

ggplot(df, aes(thresholds, accuracies)) + geom_line() + 
  geom_vline(xintercept = optimal_threshold) +
  theme_bw() + ylab("Accuracy of prediction") + xlab("Total NEE during pulse events") +
    scale_fill_manual(values=c("#3c5488", "#00a087", "#f39b7f", "#f45b7f", "#f50b7f")) +
  scale_color_manual(values=c("#3c5488", "#00a087", "#f39b7f", "#f45b7f", "#f50b7f"))

```

```{r}
png("/Users/ngocnguyen/Library/CloudStorage/Box-Box/Projects/Birch_effect_paper/Results/Figures/19_sites_manual/ML_manual_compare_test.png",  width     = 3,
    height    = 4,
    units     = "in",
    res       = 1200,
    pointsize = 4)
ggplot(melt(metric_merge_per), aes(x = variable, y = value, fill = variable)) +   
  scale_fill_manual(values=c("#3c5488", "#00a087", "#f39b7f", "#f45b7f", "#f50b7f")) +
  scale_color_manual(values=c("#3c5488", "#00a087", "#f39b7f", "#f45b7f", "#f50b7f")) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7) + 
  geom_jitter(alpha = 0.7,  size = 3, aes(color = variable)) + 
  theme_bw() + 
  theme(
  axis.text.y = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.title.y = element_text(size = 15),
  axis.title.x = element_text(size = 15),
  legend.text = element_text(size=10),
  legend.title = element_blank(),
  legend.position = c(0.95, 0.95),
    legend.justification = c("right", "top"),
    legend.box.just = "right",
    legend.key.size = unit(0.7, "cm"),
  panel.grid.major = element_blank() , panel.grid.minor = element_blank()) +
  ylab("% of pulse occurrence") + xlab("")
dev.off()
```


```{r}
accuracy_percentage <- df_merged_C %>%
  group_by(SITE_ID) %>%
  summarise(Percentage = mean(SOP_accuracy) * 100)
ggplot(accuracy_percentage, aes(x = SITE_ID, y = Percentage)) + geom_bar(stat = "identity") + theme_bw() +
  geom_text_repel(aes(label = SITE_ID))
```










